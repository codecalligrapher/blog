<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Aadi</title>
    <link>https://aadi-blogs.web.app/</link>
    <description>Recent content on Aadi</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>©2022 {year}</copyright>
    <lastBuildDate>Fri, 31 Mar 2023 00:00:00 +0000</lastBuildDate><atom:link href="https://aadi-blogs.web.app/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Setting Up Spark for PyTest</title>
      <link>https://aadi-blogs.web.app/code/pytest-spark/</link>
      <pubDate>Fri, 31 Mar 2023 00:00:00 +0000</pubDate>
      
      <guid>https://aadi-blogs.web.app/code/pytest-spark/</guid>
      <description>false</description>
    </item>
    
    <item>
      <title>Randomly Populating Pyspark Columns</title>
      <link>https://aadi-blogs.web.app/code/spark-rand/</link>
      <pubDate>Thu, 16 Mar 2023 00:00:00 +0000</pubDate>
      
      <guid>https://aadi-blogs.web.app/code/spark-rand/</guid>
      <description>false</description>
    </item>
    
    <item>
      <title>Dictionary for Automatically Loading Tables</title>
      <link>https://aadi-blogs.web.app/code/autoload/</link>
      <pubDate>Thu, 26 Jan 2023 00:00:00 +0000</pubDate>
      
      <guid>https://aadi-blogs.web.app/code/autoload/</guid>
      <description>false</description>
    </item>
    
    <item>
      <title>Patterns for Customizing Class Creation</title>
      <link>https://aadi-blogs.web.app/blog/custom-init-subclass/</link>
      <pubDate>Sat, 24 Dec 2022 00:00:00 +0000</pubDate>
      
      <guid>https://aadi-blogs.web.app/blog/custom-init-subclass/</guid>
      <description>__init_subclass__ was introduced in PEP 487 and according to James Powell covers every use that was previously done in metaclasses (with the one exception being implementation of protocols on types). It&amp;rsquo;s main purpose was to customize subclass creation
Just to get it out of the way, let&amp;rsquo;s see the order in which these functions are called (the other functions being __new__ and __init__)
class Parent: def __init__(self, *args, **kwargs) -&amp;gt; None: print(&#39;Parent __init__&#39;) def __new__(cls, *args, **kwargs): print(&#39;Parent __new__&#39;) return super().</description>
    </item>
    
    <item>
      <title>Metaclass for Auto Initialization</title>
      <link>https://aadi-blogs.web.app/code/initmeta/</link>
      <pubDate>Wed, 21 Dec 2022 00:00:00 +0000</pubDate>
      
      <guid>https://aadi-blogs.web.app/code/initmeta/</guid>
      <description>false</description>
    </item>
    
    <item>
      <title>Experiments customizing `__new__` in Python</title>
      <link>https://aadi-blogs.web.app/blog/customizing_new/</link>
      <pubDate>Mon, 12 Dec 2022 06:38:42 -0400</pubDate>
      
      <guid>https://aadi-blogs.web.app/blog/customizing_new/</guid>
      <description>object.__new__(cls[, ...]) __new__ is called to create a new instance of class cls. It is a static method, which takes the class of which an instances was requested as its first argument. Remaining are arguments passed into the constructor. The return value should be a new object instance (if this is not returned, the instance is not created)
Typically call super().__new(cls[, ...]).
__init__ vs __new__ According to the python docs, __new__ was for customizing instance creation when subclassing built-int types.</description>
    </item>
    
    <item>
      <title>XGBoost Evaluation Classes</title>
      <link>https://aadi-blogs.web.app/code/xgboost-eval/</link>
      <pubDate>Thu, 08 Dec 2022 00:00:00 +0000</pubDate>
      
      <guid>https://aadi-blogs.web.app/code/xgboost-eval/</guid>
      <description>false</description>
    </item>
    
    <item>
      <title>XGBoost, Imbalanced Classification and Hyperopt</title>
      <link>https://aadi-blogs.web.app/blog/hyperparamtuning/</link>
      <pubDate>Tue, 06 Dec 2022 06:38:42 -0400</pubDate>
      
      <guid>https://aadi-blogs.web.app/blog/hyperparamtuning/</guid>
      <description>This is a tutorial/explanation of how to set up XGBoost for imbalanced classification while tuning for imbalanced data.
There are three main sections:
Hyperopt/Bayesian Hyperparameter Tuning Focal and Crossentropy losses XGBoost Parameter Meanings (references are dropped as-needed)
Hyperopt The hyperopt package is associated with Bergstra et. al.. The authors argued that the performance of a given model depends both on the fundamental quality of the algorithm as well as details of its tuning (also known as its hyper-parameters).</description>
    </item>
    
    <item>
      <title>TensorFlow Custom Loop</title>
      <link>https://aadi-blogs.web.app/code/tf-loop/</link>
      <pubDate>Wed, 30 Nov 2022 00:38:42 -0400</pubDate>
      
      <guid>https://aadi-blogs.web.app/code/tf-loop/</guid>
      <description>A pattern I use for pretty-progress bars, custom logging and metric-handling in tensorflow.
&#39;&#39;&#39; This overviews the TensorFlow custom training loop in its (what I think is) most general sense. Four steps: 1. Define Model 2. Define Metrics, Optimizer and Losses 3. Define train and test (validation) functions 4. Write training loop &#39;&#39;&#39; import wandb import yaml import tensorflow as tf from tensorflow import keras from tensorflow.keras import layers import numpy as np import enlighten import logging import time from dataclasses import dataclass # STEP 0 - Set up datasets &#39;&#39;&#39; --------------------------------------------------------- STEP 1 - Define Model Define inputs, outputs and wrap using keras &#39;&#39;&#39; inputs = .</description>
    </item>
    
    <item>
      <title>Enforcing Function Implementation in Subclasses</title>
      <link>https://aadi-blogs.web.app/blog/enforce-override/</link>
      <pubDate>Wed, 09 Nov 2022 12:38:42 -0400</pubDate>
      
      <guid>https://aadi-blogs.web.app/blog/enforce-override/</guid>
      <description>This is going to get very weird, very quickly. When you create a class in Python, it looks about like the following:
class MyClass: pass Now, let&amp;rsquo;s say I create some really cool class, with a set of cool functions, but I expect my users to implement some of the functions:
from abc import abstractmethod class BaseClass: @abstractmethod def foo(self,): raise NotImplementedError So the intention is, when my user inherits the above class, they do the following:</description>
    </item>
    
    <item>
      <title>Managed Attributes in Python</title>
      <link>https://aadi-blogs.web.app/blog/metaprogramming-in-data-science/</link>
      <pubDate>Sat, 05 Nov 2022 00:38:42 -0400</pubDate>
      
      <guid>https://aadi-blogs.web.app/blog/metaprogramming-in-data-science/</guid>
      <description>In a previous post, I detailed how to maintain encapsulation using Python&amp;rsquo;s property. In this piece, I go through how/why to manage and apply validation to class attributes in an object-oriented fashion by means of a fairly plausible example.
A type is the parent class of class, therefore any class is actually a sub-type of type. The following are equivalent:
a = int(8) a = 8 type(a) # python knows to create an int without being explicit int The point of implementing custom attribute types is (in my case), for validation.</description>
    </item>
    
    <item>
      <title>Encapsulation with Python Properties</title>
      <link>https://aadi-blogs.web.app/blog/python-properties/</link>
      <pubDate>Mon, 31 Oct 2022 18:00:42 -0400</pubDate>
      
      <guid>https://aadi-blogs.web.app/blog/python-properties/</guid>
      <description>If you ever created a class in Python, you probably accessed it using dot notation (i.e. instance_name.attribute_name).
That&amp;rsquo;s python&amp;rsquo;s way of calling getattr by means of an alias:
class A: var = 10 pass a = A() # this is how Python accesses attributes getattr(a, &#39;var&#39;) 10 a.__getattribute__(&#39;var&#39;) # above is an alias for this 10 The most &amp;ldquo;pythonic&amp;rdquo; way of getting and setting attributes is using dot notation:
A.var = 11 print(A.</description>
    </item>
    
    <item>
      <title>Using Decorators to Solve Date Problems</title>
      <link>https://aadi-blogs.web.app/blog/using-decorators-to-solve-data-cleaning/</link>
      <pubDate>Sun, 23 Oct 2022 22:00:00 +0000</pubDate>
      
      <guid>https://aadi-blogs.web.app/blog/using-decorators-to-solve-data-cleaning/</guid>
      <description>A decorator is the gateway drug into the world of Python metaprogramming. In python, everything, everything, is an object (specifically a dictionary but let&amp;rsquo;s not go there). That means that we can pass in and return any object regardless of its types, especially regardless of its type.
If I define a function:
def fn(*args, **kwargs): pass and now call type on fn
type(fn) function the type is function (No surprises there).</description>
    </item>
    
    <item>
      <title>Mapping Pandas Columns</title>
      <link>https://aadi-blogs.web.app/blog/conditional-replace-pandas/</link>
      <pubDate>Wed, 19 Oct 2022 00:00:00 +0000</pubDate>
      
      <guid>https://aadi-blogs.web.app/blog/conditional-replace-pandas/</guid>
      <description>A few weeks ago I had to figure out how to perform a mapping of pandas column values to other values. This was not necessarily a discrete mapping, as in the initial column value needed to match a range.
The dataframe I was working with resembled the following:
value 0 88 1 3 2 5 3 65 4 72 5 54 And there were a set of conditions by which I needed to replace.</description>
    </item>
    
    <item>
      <title>Parsing XML with untangle</title>
      <link>https://aadi-blogs.web.app/code/untangle-xml/</link>
      <pubDate>Mon, 12 Sep 2022 06:38:42 -0400</pubDate>
      
      <guid>https://aadi-blogs.web.app/code/untangle-xml/</guid>
      <description>Given XML:
&amp;lt;?xml version=&amp;quot;1.0&amp;quot;?&amp;gt; &amp;lt;root&amp;gt; &amp;lt;child name=&amp;quot;child1&amp;quot;/&amp;gt; &amp;lt;/root&amp;gt; Python access
import untangle doc = untangle.parse(&#39;path/to/xml.xml&#39;) # gives hierarchical access child_name = doc.root.child[&#39;name&#39;] # &#39;child1&#39; </description>
    </item>
    
    <item>
      <title>Zero-Padding a CSV with AWK</title>
      <link>https://aadi-blogs.web.app/blog/awk_pad/</link>
      <pubDate>Fri, 26 Aug 2022 00:00:00 +0000</pubDate>
      
      <guid>https://aadi-blogs.web.app/blog/awk_pad/</guid>
      <description>This was purely out of sheer need, and this was the fastest way I could&amp;rsquo;ve gotten it done (I ended up learning a LOT about CLI and the awk command from this, so I&amp;rsquo;m really grateful for that)
The problem: I have a column in a utf-8 CSV file of type Integer, which should actually be type string and zero-padded up to (let&amp;rsquo;s say length N).
~/projects/awk_pad ❯ cat out.csv a,Y,1 b,N,10 c,Y,12223253 What I want, is the following (output from the cat tool):</description>
    </item>
    
    <item>
      <title>Graph Diffusion</title>
      <link>https://aadi-blogs.web.app/blog/graph-diffusion/</link>
      <pubDate>Mon, 25 Jul 2022 00:00:00 +0000</pubDate>
      
      <guid>https://aadi-blogs.web.app/blog/graph-diffusion/</guid>
      <description>This is taken from Diffusion Convolutional Neural Networks (referenced in the footer). According to the authors, a diffusion convolution scans a diffusion process across each node. Analog to biology, where the information is allowed to propagate conditional of its density and environment.
It was applied to node classification, edge classification and graph classification, but node-classification is the task I wanted to focus on. When first presented, it was a novel way to effectively apply convolutions (invariant to location and rotation), to arbitrarily-structured data (i.</description>
    </item>
    
    <item>
      <title>Sync Script</title>
      <link>https://aadi-blogs.web.app/code/sync-script/</link>
      <pubDate>Sun, 24 Jul 2022 12:38:42 -0400</pubDate>
      
      <guid>https://aadi-blogs.web.app/code/sync-script/</guid>
      <description>#!/usr/bin/zsh while getopts a: flag do case &amp;quot;${flag}&amp;quot; in a) remote=${OPTARG};; esac done echo &amp;quot;remote IP: $remote&amp;quot;; echo &amp;quot;write: $final&amp;quot;; home_dir=&amp;quot;/home/aadi/&amp;quot; storage_dir=&amp;quot;/storage/&amp;quot; # files in home HomeArray=( &amp;quot;.zshrc&amp;quot; ) if [[ $* == *--write* ]] then for arr in $HomeArray; do rsync -Pvtau $home_dir$arr aadi@$remote:$home_dir$arr done else for arr in $HomeArray; do rsync -Pvntau $home_dir$arr aadi@$remote:$home_dir$arr done fi # folders in home HomeArray=( &amp;quot;.config/alacritty&amp;quot; &amp;quot;.config/qtile&amp;quot; &amp;quot;.config/nvim&amp;quot; ) if [[ $* == *--write* ]] then for arr in $HomeArray; do rsync -Pvtau $home_dir$arr/ aadi@$remote:$home_dir$arr done else for arr in $HomeArray; do rsync -Pvntau $home_dir$arr/ aadi@$remote:$home_dir$arr done fi # files in storage SArray=( &amp;quot;reading&amp;quot; &amp;quot;research&amp;quot; ) if [[ $* == *--write* ]] then for arr in $SArray; do rsync -Pvtau $storage_dir$arr/ aadi@$remote:$home_dir$arr done else for arr in $SArray; do rsync -Pvntau $storage_dir$arr/ aadi@$remote:$home_dir$arr done fi </description>
    </item>
    
    <item>
      <title>PySpark Fill Rates</title>
      <link>https://aadi-blogs.web.app/code/pyspark-fill-rate/</link>
      <pubDate>Thu, 21 Jul 2022 06:38:42 -0400</pubDate>
      
      <guid>https://aadi-blogs.web.app/code/pyspark-fill-rate/</guid>
      <description>false</description>
    </item>
    
    <item>
      <title>Unravelling `tf.einsum`</title>
      <link>https://aadi-blogs.web.app/blog/tf-einsum/</link>
      <pubDate>Mon, 18 Jul 2022 23:00:42 -0400</pubDate>
      
      <guid>https://aadi-blogs.web.app/blog/tf-einsum/</guid>
      <description>Origin Story Recently, I was trying to disect the original DCNN Paper which utilized a diffusion kernel to more readily make use of implicit graph-structure in common tasks such as node, edge and graph classification. However, an existing implementation I fonund had a curious piece of notation which led me down the rabbithole of Tensor calculus.
Coordinates are maps used to solve a given problem. A coordinate transform allows mapping from one frame of reference to another (converting from a map of your high school, to the location of your high school in reference to where it is in the city, compared to a country-wide map).</description>
    </item>
    
    <item>
      <title>Basics of The Adjacency Matrix</title>
      <link>https://aadi-blogs.web.app/blog/matrix-graph/</link>
      <pubDate>Wed, 13 Jul 2022 06:20:42 -0400</pubDate>
      
      <guid>https://aadi-blogs.web.app/blog/matrix-graph/</guid>
      <description>This summarizes my initial set of basic notes surrounding the adjacency matrix representation of a graph
There are multiple ways of representing graph-structured data. One of the most common ways is using the adjacency matrix, where connections between nodes are represented in a row-column format.
For example:
$$ A = \begin{bmatrix} 0 &amp;amp; 1 &amp;amp; 0 \\ 1 &amp;amp; 0 &amp;amp; 1 \\ 0 &amp;amp; 1 &amp;amp; 0 \end{bmatrix} $$</description>
    </item>
    
    <item>
      <title>The Graph Neural Network</title>
      <link>https://aadi-blogs.web.app/blog/graph-neural-network/</link>
      <pubDate>Sat, 25 Jun 2022 06:38:42 -0400</pubDate>
      
      <guid>https://aadi-blogs.web.app/blog/graph-neural-network/</guid>
      <description>The Graph Neural Network (GNN) was proposed (Scarselli, 2008) as a general framework for defining deep neural networks on graph data.
(If you need a refresher on deep learning, see here)
The idea was to somehow utilize a deep neural network to generate node-embeddings in a generalize-able way to graph-structured data. The main idea in utilizing neural networks was that, apart from node features (degree, attributes, etc), the actual structure of the node&amp;rsquo;s neighbourhood, and by extension the graph, should contribute somehow to the node embeddings.</description>
    </item>
    
    <item>
      <title>Prefetching Memory in CUDA</title>
      <link>https://aadi-blogs.web.app/blog/prefetch-cuda/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://aadi-blogs.web.app/blog/prefetch-cuda/</guid>
      <description>Threads, Blocks and Grids A thread is a single &amp;ldquo;process&amp;rdquo; on GPU. Any given GPU kernel can use blocks of threads, grouped into a grid of blocks. A kernel is executed as a grid of blocks of threads. Each block is run by a single Streaming Multiprocessor (SM) and in most usual, single-node cases can&amp;rsquo;t be migrated to other SMs. One SM may execute several CUDA blocks concurrently.
Paging Paging is a memory-management technique which allows a process&amp;rsquo;s physical address space to be non-contiguous.</description>
    </item>
    
  </channel>
</rss>
