<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/"><channel><title>Blogs on Aadis Blog</title><link>https://aadi-blogs.web.app/blog/</link><description>Recent content in Blogs on Aadis Blog</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Sun, 23 Oct 2022 22:00:00 +0000</lastBuildDate><atom:link href="https://aadi-blogs.web.app/blog/index.xml" rel="self" type="application/rss+xml"/><item><title>Using Decorators to Solve Date Problems</title><link>https://aadi-blogs.web.app/blog/using-decorators-to-solve-data-cleaning/</link><pubDate>Sun, 23 Oct 2022 22:00:00 +0000</pubDate><guid>https://aadi-blogs.web.app/blog/using-decorators-to-solve-data-cleaning/</guid><description>A decorator is the gateway drug into the world of Python metaprogramming. In python, everything, everything, is an object (specifically a dictionary but let&amp;rsquo;s not go there). That means that we can pass in and return any object regardless of its types, especially regardless of its type.
If I define a function:
def fn(*args, **kwargs): pass and now call type on fn
type(fn) function the type is function (No surprises there).</description></item><item><title>Mapping Pandas Columns</title><link>https://aadi-blogs.web.app/blog/conditional-replace-pandas/</link><pubDate>Wed, 19 Oct 2022 00:00:00 +0000</pubDate><guid>https://aadi-blogs.web.app/blog/conditional-replace-pandas/</guid><description>A few weeks ago I had to figure out how to perform a mapping of pandas column values to other values. This was not necessarily a discrete mapping, as in the initial column value needed to match a range.
The dataframe I was working with resembled the following:
value 0 88 1 3 2 5 3 65 4 72 5 54 And there were a set of conditions by which I needed to replace.</description></item><item><title>Zero-Padding a CSV with AWK</title><link>https://aadi-blogs.web.app/blog/awk_pad/</link><pubDate>Fri, 26 Aug 2022 00:00:00 +0000</pubDate><guid>https://aadi-blogs.web.app/blog/awk_pad/</guid><description>This was purely out of sheer need, and this was the fastest way I could&amp;rsquo;ve gotten it done (I ended up learning a LOT about CLI and the awk command from this, so I&amp;rsquo;m really grateful for that)
The problem: I have a column in a utf-8 CSV file of type Integer, which should actually be type string and zero-padded up to (let&amp;rsquo;s say length N).
~/projects/awk_pad ‚ùØ cat out.csv a,Y,1 b,N,10 c,Y,12223253 What I want, is the following (output from the cat tool):</description></item><item><title>Graph Diffusion</title><link>https://aadi-blogs.web.app/blog/graph-diffusion/</link><pubDate>Mon, 25 Jul 2022 00:00:00 +0000</pubDate><guid>https://aadi-blogs.web.app/blog/graph-diffusion/</guid><description>This is taken from Diffusion Convolutional Neural Networks (referenced in the footer). According to the authors, a diffusion convolution scans a diffusion process across each node. Analog to biology, where the information is allowed to propagate conditional of its density and environment.
It was applied to node classification, edge classification and graph classification, but node-classification is the task I wanted to focus on. When first presented, it was a novel way to effectively apply convolutions (invariant to location and rotation), to arbitrarily-structured data (i.</description></item><item><title>Unravelling `tf.einsum`</title><link>https://aadi-blogs.web.app/blog/tf-einsum/</link><pubDate>Mon, 18 Jul 2022 23:00:42 -0400</pubDate><guid>https://aadi-blogs.web.app/blog/tf-einsum/</guid><description>Origin Story Recently, I was trying to disect the original DCNN Paper which utilized a diffusion kernel to more readily make use of implicit graph-structure in common tasks such as node, edge and graph classification. However, an existing implementation I fonund had a curious piece of notation which led me down the rabbithole of Tensor calculus.
Coordinates are maps used to solve a given problem. A coordinate transform allows mapping from one frame of reference to another (converting from a map of your high school, to the location of your high school in reference to where it is in the city, compared to a country-wide map).</description></item><item><title>Basics of The Adjacency Matrix</title><link>https://aadi-blogs.web.app/blog/matrix-graph/</link><pubDate>Wed, 13 Jul 2022 06:20:42 -0400</pubDate><guid>https://aadi-blogs.web.app/blog/matrix-graph/</guid><description>This summarizes my initial set of basic notes surrounding the adjacency matrix representation of a graph
There are multiple ways of representing graph-structured data. One of the most common ways is using the adjacency matrix, where connections between nodes are represented in a row-column format.
For example:
$$ A = \begin{bmatrix} 0 &amp;amp; 1 &amp;amp; 0 \\ 1 &amp;amp; 0 &amp;amp; 1 \\ 0 &amp;amp; 1 &amp;amp; 0 \end{bmatrix} $$</description></item><item><title>The Graph Neural Network</title><link>https://aadi-blogs.web.app/blog/graph-neural-network/</link><pubDate>Sat, 25 Jun 2022 06:38:42 -0400</pubDate><guid>https://aadi-blogs.web.app/blog/graph-neural-network/</guid><description>The Graph Neural Network (GNN) was proposed (Scarselli, 2008) as a general framework for defining deep neural networks on graph data.
(If you need a refresher on deep learning, see here)
The idea was to somehow utilize a deep neural network to generate node-embeddings in a generalize-able way to graph-structured data. The main idea in utilizing neural networks was that, apart from node features (degree, attributes, etc), the actual structure of the node&amp;rsquo;s neighbourhood, and by extension the graph, should contribute somehow to the node embeddings.</description></item><item><title>Prefetching Memory in CUDA</title><link>https://aadi-blogs.web.app/blog/prefetch-cuda/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aadi-blogs.web.app/blog/prefetch-cuda/</guid><description>Threads, Blocks and Grids A thread is a single &amp;ldquo;process&amp;rdquo; on GPU. Any given GPU kernel can use blocks of threads, grouped into a grid of blocks. A kernel is executed as a grid of blocks of threads. Each block is run by a single Streaming Multiprocessor (SM) and in most usual, single-node cases can&amp;rsquo;t be migrated to other SMs. One SM may execute several CUDA blocks concurrently.
Paging Paging is a memory-management technique which allows a process&amp;rsquo;s physical address space to be non-contiguous.</description></item></channel></rss>